from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI
import os
import logging
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import PlainTextResponse
from fastapi.responses import JSONResponse
import logging
import json
import re



client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# –õ–æ–≥–µ—Ä
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("/app/uvicorn.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class NativeLikeRequest(BaseModel):
    text: str

class ThoughtsRequest(BaseModel):
    text: str

PHRASES_FILE = "data/user_phrases.json"

class PhraseRequest(BaseModel):
    text: str

@app.post("/thoughts-dictionary")
def extract_thought_blocks(data: ThoughtsRequest):
    user_text = data.text
    logging.info(f"üß† –¢–µ–∫—Å—Ç –¥–ª—è —Å–ª–æ–≤–Ω–∏–∫–∞ –¥—É–º–æ–∫: {user_text}")

    try:
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–í–∏—Ç—è–≥—É–π –∑ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç—É 10 –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞–Ω–≥–ª—ñ–π—Å—å–∫–∏—Ö —Ñ—Ä–∞–∑ (2-6 —Å–ª—ñ–≤), —è–∫—ñ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—é—Ç—å –æ—Å–Ω–æ–≤–Ω—ñ –¥—É–º–∫–∏, –¥—ñ—ó —á–∏ —Å—Ç–∞–Ω–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞."
                        "–§—Ä–∞–∑–∏ –Ω–µ –æ–±–æ–≤'—è–∑–∫–æ–≤–æ –º–∞—é—Ç—å –±—É—Ç–∏ —Ç–æ—á–Ω–∏–º–∏ —Ü–∏—Ç–∞—Ç–∞–º–∏ ‚Äî –≥–æ–ª–æ–≤–Ω–µ, —â–æ–± –≤–æ–Ω–∏ –±—É–ª–∏ –±–ª–∏–∑—å–∫–∏–º–∏ –∑–∞ –∑–º—ñ—Å—Ç–æ–º –¥–æ —Ç–æ–≥–æ, —â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –æ–ø–∏—Å—É—î."
                        "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Ç–∞–∫—ñ —Ñ—Ä–∞–∑–∏, —â–æ –º–∞—é—Ç—å –∑–∞–∫—ñ–Ω—á–µ–Ω–∏–π —Å–º–∏—Å–ª —ñ –º–æ–∂—É—Ç—å –±—É—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –æ–∫—Ä–µ–º–æ."
                        "–†–æ–±–∏ —Ü–µ –Ω–∞—á–µ —Ü–µ —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç—É, –∞–ª–µ –∑ —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–æ—Ä–æ—Ç–∫—ñ —Ñ—Ä–∞–∑–∏, —è–∫—ñ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—é—Ç—å —Å—É—Ç—å –¥—É–º–æ–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞."
                        
                        "–î–æ –∫–æ–∂–Ω–æ—ó –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—ó —Ñ—Ä–∞–∑–∏ –¥–æ–¥–∞–π –ø–µ—Ä–µ–∫–ª–∞–¥ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. "
                        "–ü–æ–≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON-—Å–ø–∏—Å–∫—É –æ–±'—î–∫—Ç—ñ–≤: [{\"en\": \"phrase\", \"uk\": \"–ø–µ—Ä–µ–∫–ª–∞–¥\"}, ...]"
                    )
                },
                {
                    "role": "user",
                    "content": data.text
                }
            ],
            temperature=0.3,
        )


        # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
        content = response.choices[0].message.content.strip()
        logging.info(f"‚úÖ –û—Ç—Ä–∏–º–∞–Ω—ñ –±–ª–æ–∫–∏: {content}")

        return {
            "phrases": content
        }

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —É ChatCompletion: {e}")
        return {
            "phrases": [],
            "error": str(e)
        }

@app.post("/nativelike")
def analyze_native_like(data: NativeLikeRequest):
    logger.info("‚û°Ô∏è  –û—Ç—Ä–∏–º–∞–Ω–æ –∑–∞–ø–∏—Ç –Ω–∞ /nativelike")
    logger.info(f"üì© –í–≤–µ–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç: {data.text}")

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"""
–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ä–µ—á–µ–Ω–Ω—è –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é: "{data.text}"

1. –ß–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–µ –≤–æ–Ω–æ –≥—Ä–∞–º–∞—Ç–∏—á–Ω–æ/–ª–µ–∫—Å–∏—á–Ω–æ?
2. –Ø–∫—â–æ –Ω—ñ ‚Äî —è–∫ —Ü–µ —Å–ø—Ä–∏–π–º–∞—î—Ç—å—Å—è –Ω–∞ —Å–ª—É—Ö (—É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é), —è–∫ –±–∏ —Ü–µ "–∑–≤—É—á–∞–ª–æ" –≤—ñ–¥ –Ω–µ-–Ω–µ–π—Ç–∏–≤–∞?

–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É JSON:
{{
  "is_correct": true/false,
  "native_perception": "..."
}}
                """
            }],
            temperature=0.3,
        )

        content = response.choices[0].message.content
        logger.info(f"‚úÖ –í—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ OpenAI: {content}")

        return {
            "is_correct": False,  # —Ç–∏–º—á–∞—Å–æ–≤–æ
            "native_perception": content
        }

    except Exception as e:
        logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ –¥–æ OpenAI: {str(e)}")
        return {
            "is_correct": False,
            "native_perception": "–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª—ñ–∑—ñ —Ç–µ–∫—Å—Ç—É.",
            "error": str(e)
        }

@app.get("/phrases-file-json")
def get_phrases_json():
    try:
        with open("data/user_phrases.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            return JSONResponse(content=data)
    except Exception as e:
        logging.error(f"‚ùå Error reading user_phrases.json: {e}")
        return JSONResponse(content={"error": str(e)}, status_code=500)

@app.post("/analyze-and-append")
def analyze_and_append(data: PhraseRequest):
    user_text = data.text.strip()
    logging.info(f"üì© User input: {user_text}")

    try:
        prompt = f"""
        You're a language assistant. Analyze this sentence:
        "{user_text}"

        Return only valid JSON in this structure:

        {{
          "original": "...",
          "fixed": "...",
          "issue": "...",
          "issues": {{
            "Articles": 0,
            "WordOrder": 0,
            "VerbTenses": 0,
            "SubjectVerbAgreement": 0,
            "Prepositions": 0,
            "WordChoice": 0,
            "QuestionFormation": 0,
            "BusinessTone": 0,
            "SentenceFlow": 0,
            "Spelling": 0
          }}
        }}

        No comments, no explanation ‚Äî only JSON.
        """

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )

        raw = response.choices[0].message.content.strip()
        logging.info("üì¶ Raw GPT response:\n" + raw)

        # DEBUG: print all characters with their indexes
        for idx, char in enumerate(raw):
            logging.debug(f"[{idx}] {repr(char)}")

        # Try naive parse first
        try:
            parsed = json.loads(raw)
            logging.info(f"‚úÖ JSON loaded directly")
        except json.JSONDecodeError as e:
            logging.warning(f"‚ö†Ô∏è Direct parse failed: {e}")
            logging.warning("üîç Trying regex-based extraction...")

            # Try extracting first JSON block
            match = re.search(r"\{.*\}", raw, re.DOTALL)
            if not match:
                raise ValueError("üõë Could not find JSON block with regex!")

            raw_json = match.group()
            logging.info("üîß Extracted JSON block:\n" + raw_json)

            parsed = json.loads(raw_json)
            logging.info("‚úÖ JSON loaded from extracted block")


        # Step 4: –î–æ–±–∞–≤–∏—Ç—å –≤ user_phrases.json
        try:
            logging.debug(f"üìÇ Trying to open {PHRASES_FILE} for reading...")
            with open("data/user_phrases.json", "r", encoding="utf-8") as f:
                phrases = json.load(f)
                logging.debug(f"üìÑ Current content in file ({len(phrases)} phrases): {phrases[:1]}")
        except FileNotFoundError:
            logging.warning(f"üìÅ {PHRASES_FILE} not found. Creating new list.")
            phrases = []
        except json.JSONDecodeError as e:
            logging.error(f"‚ùå Failed to parse JSON from {PHRASES_FILE}: {e}")
            phrases = []

        # Insert new phrase
        logging.debug("‚ûï Inserting new parsed entry at the top of the list.")
        phrases.insert(0, parsed)

        try:
            logging.debug(f"üíæ Writing {len(phrases)} total phrases back to {PHRASES_FILE}...")
            with open(PHRASES_FILE, "w", encoding="utf-8") as f:
                json.dump(phrases, f, indent=2, ensure_ascii=False)
            logging.info("‚úÖ Saved successfully to user_phrases.json")
        except Exception as e:
            logging.error(f"‚ùå Failed to write to {PHRASES_FILE}: {e}")
            raise
                # Step 5: Update statistics.json
        try:
            with open("data/statistics.json", "r", encoding="utf-8") as f:
                stats = json.load(f)
            logging.info("üìä Loaded existing statistics.json")
        except FileNotFoundError:
            stats = {key: 0 for key in parsed["issues"].keys()}
            logging.info("üìä Created new statistics.json")

        # –°—É–º–∞ –ø–æ –∫–æ–∂–Ω—ñ–π –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        for key, value in parsed["issues"].items():
            stats[key] = stats.get(key, 0) + value

        with open("data/statistics.json", "w", encoding="utf-8") as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)

        logging.info("‚úÖ Updated statistics.json")

        # Save as usual
        return {"success": True, "entry": parsed}

    except Exception as e:
        logging.error(f"‚ùå Final error: {str(e)}")
        return {"success": False, "error": str(e)}




@app.get("/statistics")
def get_statistics():
    try:
        with open("data/statistics.json", "r", encoding="utf-8") as f:
            stats = json.load(f)
        return JSONResponse(content=stats)
    except Exception as e:
        logging.error(f"‚ùå Failed to load statistics: {e}")
        return JSONResponse(content={"error": "Could not load statistics"}, status_code=500)        
from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI
import os
import logging
from fastapi.middleware.cors import CORSMiddleware

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# –õ–æ–≥–µ—Ä
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("/app/uvicorn.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class NativeLikeRequest(BaseModel):
    text: str

class ThoughtsRequest(BaseModel):
    text: str

@app.post("/thoughts-dictionary")
def extract_thought_blocks(data: ThoughtsRequest):
    user_text = data.text
    logging.info(f"üß† –¢–µ–∫—Å—Ç –¥–ª—è —Å–ª–æ–≤–Ω–∏–∫–∞ –¥—É–º–æ–∫: {user_text}")

    try:
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–í–∏—Ç—è–≥—É–π –∑ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç—É 10 –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞–Ω–≥–ª—ñ–π—Å—å–∫–∏—Ö —Ñ—Ä–∞–∑ (2-6 —Å–ª—ñ–≤), —è–∫—ñ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—é—Ç—å –æ—Å–Ω–æ–≤–Ω—ñ –¥—É–º–∫–∏, –¥—ñ—ó —á–∏ —Å—Ç–∞–Ω–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞."
                        "–§—Ä–∞–∑–∏ –Ω–µ –æ–±–æ–≤'—è–∑–∫–æ–≤–æ –º–∞—é—Ç—å –±—É—Ç–∏ —Ç–æ—á–Ω–∏–º–∏ —Ü–∏—Ç–∞—Ç–∞–º–∏ ‚Äî –≥–æ–ª–æ–≤–Ω–µ, —â–æ–± –≤–æ–Ω–∏ –±—É–ª–∏ –±–ª–∏–∑—å–∫–∏–º–∏ –∑–∞ –∑–º—ñ—Å—Ç–æ–º –¥–æ —Ç–æ–≥–æ, —â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –æ–ø–∏—Å—É—î."
                        "–î–æ –∫–æ–∂–Ω–æ—ó –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—ó —Ñ—Ä–∞–∑–∏ –¥–æ–¥–∞–π –ø–µ—Ä–µ–∫–ª–∞–¥ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. "
                        "–ü–æ–≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON-—Å–ø–∏—Å–∫—É –æ–±'—î–∫—Ç—ñ–≤: [{\"en\": \"phrase\", \"uk\": \"–ø–µ—Ä–µ–∫–ª–∞–¥\"}, ...]"
                    )
                },
                {
                    "role": "user",
                    "content": data.text
                }
            ],
            temperature=0.3,
        )


        # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
        content = response.choices[0].message.content.strip()
        logging.info(f"‚úÖ –û—Ç—Ä–∏–º–∞–Ω—ñ –±–ª–æ–∫–∏: {content}")

        return {
            "phrases": content
        }

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —É ChatCompletion: {e}")
        return {
            "phrases": [],
            "error": str(e)
        }

@app.post("/nativelike")
def analyze_native_like(data: NativeLikeRequest):
    logger.info("‚û°Ô∏è  –û—Ç—Ä–∏–º–∞–Ω–æ –∑–∞–ø–∏—Ç –Ω–∞ /nativelike")
    logger.info(f"üì© –í–≤–µ–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç: {data.text}")

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"""
–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ä–µ—á–µ–Ω–Ω—è –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é: "{data.text}"

1. –ß–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–µ –≤–æ–Ω–æ –≥—Ä–∞–º–∞—Ç–∏—á–Ω–æ/–ª–µ–∫—Å–∏—á–Ω–æ?
2. –Ø–∫—â–æ –Ω—ñ ‚Äî —è–∫ —Ü–µ —Å–ø—Ä–∏–π–º–∞—î—Ç—å—Å—è –Ω–∞ —Å–ª—É—Ö (—É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é), —è–∫ –±–∏ —Ü–µ "–∑–≤—É—á–∞–ª–æ" –≤—ñ–¥ –Ω–µ-–Ω–µ–π—Ç–∏–≤–∞?

–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É JSON:
{{
  "is_correct": true/false,
  "native_perception": "..."
}}
                """
            }],
            temperature=0.3,
        )

        content = response.choices[0].message.content
        logger.info(f"‚úÖ –í—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ OpenAI: {content}")

        return {
            "is_correct": False,  # —Ç–∏–º—á–∞—Å–æ–≤–æ
            "native_perception": content
        }

    except Exception as e:
        logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ –¥–æ OpenAI: {str(e)}")
        return {
            "is_correct": False,
            "native_perception": "–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª—ñ–∑—ñ —Ç–µ–∫—Å—Ç—É.",
            "error": str(e)
        }
